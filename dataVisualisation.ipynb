{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMP9517 Group Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration & Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will do some preliminary data exploration to understand what is contained in this dataset. Since this is a novel dataset, there is no guarantee that the data is complete, or that every single photo contains at least one head, carapace, and fin. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.69s)\n",
      "creating index...\n",
      "index created!\n",
      "\n",
      "----------------- Dataset Information -----------------\n",
      "\n",
      "Number of images in dataset:  8729\n",
      "\n",
      "All categories are expected in dataset\n"
     ]
    }
   ],
   "source": [
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Load in annotations file\n",
    "annotation_file = 'turtles-data/data/annotations.json'\n",
    "coco = COCO(annotation_file)\n",
    "print(\"\\n----------------- Dataset Information -----------------\\n\")\n",
    "\n",
    "# Count number of images for our dataset\n",
    "image_ids = coco.getImgIds()\n",
    "num_images = len(image_ids)\n",
    "print(\"Number of images in dataset: \", num_images)\n",
    "\n",
    "# Identify the number of categories in our dataset\n",
    "coco.loadCats(coco.getCatIds())\n",
    "category_ids = coco.loadCats(coco.getCatIds())\n",
    "categories = {category['id']: category['name'] for category in category_ids}\n",
    "\n",
    "# Ensure there are no additonal categories that we did not expect\n",
    "expected_categories = {'turtle', 'head', 'flipper'}\n",
    "if set(categories.values()) != expected_categories:\n",
    "    raise ValueError(f\"Unexpected categories in dataset {categories}\")\n",
    "else:\n",
    "    print(\"\\nAll categories are expected in dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID: 1, Name: turtle\n",
      "ID: 2, Name: flipper\n",
      "ID: 3, Name: head\n"
     ]
    }
   ],
   "source": [
    "cat_ids = coco.getCatIds()\n",
    "categories = coco.loadCats(cat_ids)\n",
    "\n",
    "# Print out each category's information and order\n",
    "for category in categories:\n",
    "    print(f\"ID: {category['id']}, Name: {category['name']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "category_names = [\"turtle\", \"flipper\", \"head\"]  # Mistake found ! Make sure to maintain order\n",
    "cat_ids = coco.getCatIds(catNms=category_names)\n",
    "\n",
    "# Create a dictionary to count how many counts of each category there are in each image\n",
    "category_counts = {'image_id': [], 'turtle': [], 'flipper': [], 'head': []}\n",
    "\n",
    "# Loop over each image\n",
    "img_ids = coco.getImgIds()\n",
    "for img_id in img_ids:\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids)\n",
    "    anns = coco.loadAnns(ann_ids)\n",
    "\n",
    "    # Append the current image ID\n",
    "    category_counts[\"image_id\"].append(img_id)\n",
    "\n",
    "    # Count number of each category for current image ID\n",
    "    category_counts[\"turtle\"].append(\n",
    "        sum(ann[\"category_id\"] == cat_ids[0] for ann in anns)\n",
    "    )\n",
    "    category_counts[\"flipper\"].append(\n",
    "        sum(ann[\"category_id\"] == cat_ids[1] for ann in anns)\n",
    "    )\n",
    "    category_counts[\"head\"].append(\n",
    "        sum(ann[\"category_id\"] == cat_ids[2] for ann in anns)\n",
    "    )\n",
    "\n",
    "# Convert to dataframe\n",
    "category_counts_df = pd.DataFrame(category_counts)\n",
    "category_sums = category_counts_df[[\"turtle\", \"flipper\", \"head\"]].sum()\n",
    "\n",
    "# Totals for each category\n",
    "plt.figure(figsize=(20, 10))\n",
    "category_sums.plot(kind=\"bar\", color=[\"seagreen\", \"mediumslateblue\", \"khaki\"])\n",
    "plt.title(\"Total Count of Labels in Dataset\")\n",
    "plt.xlabel(\"Category\")\n",
    "plt.ylabel(\"Total Count\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(20, 10))\n",
    "for i, category in enumerate([\"turtle\", \"flipper\", \"head\"]):\n",
    "    plt.subplot(1, 3, i + 1)\n",
    "    sns.histplot(category_counts_df[category], kde=True, bins=20)\n",
    "    plt.title(f\"Distribution of '{category}' Counts per Image\")\n",
    "    plt.xlabel(\"Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset contains 8729 images. Some images may not contain a turtle, head, or flipper so we will investigate these files manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images missing 'turtle' label: 20\n",
      "\n",
      "Number of images missing 'flipper' label: 101\n",
      "\n",
      "Number of images missing 'head' label: 203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "required_categories = [\"turtle\", \"flipper\", \"head\"]\n",
    "cat_ids = coco.getCatIds(catNms=required_categories)\n",
    "cat_ids_map = dict(zip(category_names, cat_ids))\n",
    "\n",
    "missing_labels_images = {category: 0 for category in required_categories}\n",
    "img_ids = coco.getImgIds()\n",
    "\n",
    "for img_id in img_ids:\n",
    "    missing_categories = []\n",
    "    for category, cat_id in cat_ids_map.items():\n",
    "        ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_id)\n",
    "        if not ann_ids:\n",
    "            missing_categories.append(category)\n",
    "\n",
    "    for category in missing_categories:\n",
    "        missing_labels_images[category] += 1\n",
    "\n",
    "# Report results\n",
    "for category, count in missing_labels_images.items():\n",
    "    print(f\"Number of images missing '{category}' label: {count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the ones without a turtle to investigate what is going on with the missing labels\n",
    "\n",
    "missing_turtle_img_ids = []\n",
    "for img_id in img_ids:\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids_map[\"turtle\"])\n",
    "    if not ann_ids:\n",
    "        missing_turtle_img_ids.append(img_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def load_images(missing_part_images_ids):\n",
    "    for image_id in missing_part_images_ids:\n",
    "\n",
    "        # Debug missing images\n",
    "        try:\n",
    "            img = coco.loadImgs(image_id)[0]\n",
    "        except TypeError:\n",
    "            print(f\"This image ID is missing: {image_id}\")\n",
    "            continue\n",
    "\n",
    "        image = np.array(Image.open(f\"turtles-data/data/{img['file_name']}\"))\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Original Image\")\n",
    "\n",
    "        # Annotations\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(image)\n",
    "        cat_ids = coco.getCatIds()\n",
    "        ann_ids = coco.getAnnIds(imgIds=img[\"id\"], catIds=cat_ids, iscrowd=None)\n",
    "        anns = coco.loadAnns(ann_ids)\n",
    "        coco.showAnns(anns)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Annotations\")\n",
    "\n",
    "        # Masked\n",
    "        plt.subplot(1, 3, 3)\n",
    "        mask = np.zeros((img[\"height\"], img[\"width\"]), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            mask += coco.annToMask(ann)\n",
    "        plt.imshow(mask, cmap=\"plasma\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Masked\")\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# NOTE! Unload these cells before pushing to git to avoid making the file too large.\n",
    "# Clear the output of the cells above before pushing to git.\n",
    "\"\"\"\n",
    "\n",
    "load_images(missing_turtle_img_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the images above, the dataset quality is quite concerning. We will do the same for the other datasets which are missing labels with the exact same method as above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of images missing 'head' label: 203\n",
      "Number of images missing 'flipper' label: 101\n"
     ]
    }
   ],
   "source": [
    "# Load in files again in case of lost or incorrect reference\n",
    "# annotation_file = \"turtles-data/data/annotations.json\"\n",
    "# coco = COCO(annotation_file)\n",
    "image_ids = coco.getImgIds()\n",
    "\n",
    "missing_head_image_ids = []\n",
    "missing_flipper_image_ids = []\n",
    "\n",
    "for img_id in image_ids:\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids_map[\"head\"])\n",
    "    if not ann_ids:\n",
    "        missing_head_image_ids.append(img_id)\n",
    "\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids_map[\"flipper\"])\n",
    "    if not ann_ids:\n",
    "        missing_flipper_image_ids.append(img_id)\n",
    "\n",
    "print(f\"Number of images missing 'head' label: {len(missing_head_image_ids)}\")\n",
    "print(f\"Number of images missing 'flipper' label: {len(missing_flipper_image_ids)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "# NOTE! Unload these cells before pushing to git to avoid making the file too large.\n",
    "# Clear the output of the cells above before pushing to git.\n",
    "# Since there are 304 images missing the head label, this is extra important!\n",
    "\"\"\"\n",
    "\n",
    "load_images(missing_head_image_ids)\n",
    "load_images(missing_flipper_image_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Cleanup & Re-validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we will directly edit and delete the unnecessary files of the COCO dataset. Based on the analysis done in the section above, we will only delete the 20 images that are labelled with no turtle as every single datapoint there have quite significant errors in their annotation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will need to refetch all references to the COCO objects as well as the imageIDs of the errornous dataset\n",
    "# images... Please make sure you run this on your own machine prior to training the model.\n",
    "\n",
    "import json\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Load in annotations file\n",
    "annotation_file = \"turtles-data/data/annotations.json\"\n",
    "coco = COCO(annotation_file)\n",
    "print(\"\\n----------------- Before Cleanup -----------------\\n\")\n",
    "\n",
    "# Count number of images for our dataset\n",
    "image_ids = coco.getImgIds()\n",
    "num_images = len(image_ids)\n",
    "print(\"Number of images in dataset: \", num_images) # 8729 -> 8709\n",
    "\n",
    "# Identify the number of categories in our dataset\n",
    "category_ids = coco.loadCats(coco.getCatIds())\n",
    "categories = {category[\"id\"]: category[\"name\"] for category in category_ids}\n",
    "\n",
    "# Find the ones that are missing the turtle label\n",
    "missing_turtle_img_ids = []\n",
    "for img_id in image_ids:\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids_map[\"turtle\"])\n",
    "    if not ann_ids:\n",
    "        missing_turtle_img_ids.append(img_id)\n",
    "print(f\"Number of images missing 'turtle' label: {len(missing_turtle_img_ids)}\")\n",
    "\n",
    "print(f\"\\nRemoving these images from the dataset...\\n\")\n",
    "\n",
    "# Begin the purge\n",
    "with open(annotation_file, 'r') as f:\n",
    "    coco_data = json.load(f)\n",
    "\n",
    "# Remove images and annotations from JSON\n",
    "coco_data['images'] = [img for img in coco_data['images'] if img['id'] not in missing_turtle_img_ids]\n",
    "coco_data['annotations'] = [ann for ann in coco_data['annotations'] if ann['image_id'] not in missing_turtle_img_ids]\n",
    "\n",
    "# Save as a new updated JSON file\n",
    "with open(\"turtles-data/data/updated_annotations.json\", 'w') as f:\n",
    "    json.dump(coco_data, f)\n",
    "print(\"\\n----------------- After Cleanup -----------------\\n\")\n",
    "print(\"Updated annotations saved to 'turtles-data/data/updated_annotations.json'. Please use this from now on!\")\n",
    "\n",
    "# Delete image files\n",
    "images_path = \"turtles-data/data/\"\n",
    "for img_id in missing_turtle_img_ids:\n",
    "    img_info = coco.loadImgs([img_id])[0]\n",
    "    img_file_path = os.path.join(images_path, img_info['file_name'])\n",
    "    if os.path.exists(img_file_path):\n",
    "        os.remove(img_file_path)\n",
    "        print(f\"[SUCCESS]: Deleted image file: {img_file_path}\")\n",
    "    else:\n",
    "        print(f\"[ERROR!]: Image file not found: {img_file_path}\")\n",
    "\n",
    "print(\"All files without turtles have been deleted successfully!\")\n",
    "\n",
    "# Load in new annotations as validation\n",
    "annotation_file = \"turtles-data/data/updated_annotations.json\"\n",
    "coco = COCO(annotation_file)\n",
    "image_ids = coco.getImgIds()\n",
    "num_images = len(image_ids)\n",
    "print(\"Number of images in dataset: \", num_images)\n",
    "\n",
    "# Find the ones that are missing the turtle label\n",
    "missing_turtle_img_ids = []\n",
    "for img_id in image_ids:\n",
    "    ann_ids = coco.getAnnIds(imgIds=img_id, catIds=cat_ids_map[\"turtle\"])\n",
    "    if not ann_ids:\n",
    "        missing_turtle_img_ids.append(img_id)\n",
    "print(f\"Number of images missing 'turtle' label: {len(missing_turtle_img_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please note: Use updated_annotations.json from this point onwards, annotations.json will not be correct!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another issue we did not yet take into consideration is the size of each image, for image segmentation task we should normalise all pictures to a single size. If there are any issues, we will need to fix them as well as their segmentation masks, but we will first check if there is a need for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "def check_image_sizes(folder_path):\n",
    "    size_counts = defaultdict(int)\n",
    "    total_images = 0\n",
    "\n",
    "    for root, dirs, files in os.walk(folder_path):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(\n",
    "                (\".png\", \".jpg\", \".jpeg\")\n",
    "            ):\n",
    "                img_path = os.path.join(root, file)\n",
    "                with Image.open(img_path) as img:\n",
    "                    img_size = img.size\n",
    "\n",
    "                    # Save this image size to the approrpiate resolution key\n",
    "                    size_counts[img_size] += 1\n",
    "                    total_images += 1\n",
    "\n",
    "    # Print the results\n",
    "    print(f\"\\n----------------- Image Size Verification -----------------\\n\")\n",
    "    print(f\"Total images checked: {total_images}\")\n",
    "    if len(size_counts) == 1:\n",
    "        print(\"All images have the same size:\", list(size_counts.keys())[0])\n",
    "    else:\n",
    "        print(\"Image size counts:\")\n",
    "        for size, count in size_counts.items():\n",
    "            print(f\"Size {size}: {count} images\")\n",
    "\n",
    "check_image_sizes(\"turtles-data/data/images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, it is clear that this dataset has not been processed in any way by the original publisher and we will need to process it ourselves. Luckily, we can use albumentations, a powerful community built library to transform data in instance segmentation for both images as well as their segmentation spatial transformations. We will reshape all images to a default size of 2000 x 1333, as it seems like most images follow this size. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as A\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "resize_transform = A.Compose(\n",
    "    [\n",
    "        A.Resize(2000, 1333, p=1),  # Resize to 2000x1333\n",
    "        A.Normalize(),  # Normalises pixel values\n",
    "        ToTensorV2(),  # Converts to PyTorch tensor\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(format=\"coco\", label_fields=[\"category_ids\"]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "\n",
    "class customTurtleDataset(Dataset):\n",
    "    def __init__(self, root, annotation, transforms=None, target_size=(2000, 1333)):\n",
    "        self.root = root\n",
    "        self.coco = COCO(annotation)\n",
    "        self.transforms = transforms\n",
    "        self.img_ids = list(self.coco.imgs.keys())\n",
    "        self.target_size = target_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_ids)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Image params\n",
    "        img_id = self.img_ids[idx]\n",
    "        img_info = self.coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(self.root, img_info[\"file_name\"])\n",
    "        img = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "        # Annotations\n",
    "        ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
    "        anns = self.coco.loadAnns(ann_ids)\n",
    "\n",
    "        # BBox and category IDs\n",
    "        bbox = [ann[\"bbox\"] for ann in anns]\n",
    "        category_ids = [ann[\"category_id\"] for ann in anns]\n",
    "\n",
    "        # Masks from annotations\n",
    "        masks = np.zeros((img_info[\"height\"], img_info[\"width\"]), dtype=np.uint8)\n",
    "        for ann in anns:\n",
    "            masks += self.coco.annToMask(ann)\n",
    "\n",
    "        # Apply transformations\n",
    "        original_size = img.size\n",
    "        image = np.array(img)\n",
    "        if self.transforms and original_size != self.target_size:\n",
    "            transformed = self.transforms(\n",
    "                image=image, bboxes=bbox, masks=[masks], category_ids=category_ids\n",
    "            )\n",
    "            image = transformed[\"image\"]        # Resize image\n",
    "            bbox = transformed[\"bboxes\"]        # Resize bounding boxes\n",
    "            masks = transformed[\"masks\"][0]     # Resize masks\n",
    "            category_ids = transformed[\"category_ids\"]\n",
    "        else:\n",
    "            image = torch.tensor(image, dtype=torch.float32).permute(2, 0, 1)\n",
    "            masks = torch.tensor(masks, dtype=torch.uint8)\n",
    "\n",
    "        # Convert bounding boxes and category IDs to tensors\n",
    "        bboxes = torch.tensor(bbox, dtype=torch.float32)\n",
    "        category_ids = torch.tensor(category_ids, dtype=torch.int64)\n",
    "\n",
    "        return {\n",
    "            \"image\": image,\n",
    "            \"bboxes\": bboxes,\n",
    "            \"masks\": masks,\n",
    "            \"category_ids\": category_ids,\n",
    "            \"original_size\": original_size,\n",
    "            \"target_size\": self.target_size,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the resized images to verify the transformation works and the masks are still correct.\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "from pycocotools.coco import COCO\n",
    "from pycocotools import mask as mask_utils\n",
    "\n",
    "def get_wrong_size_image_ids(folder_path, coco, target_size=(2000, 1333)):\n",
    "    wrong_image_ids = []\n",
    "    for img_id in coco.getImgIds():\n",
    "        img_info = coco.loadImgs(img_id)[0]\n",
    "        img_path = os.path.join(folder_path, img_info[\"file_name\"])\n",
    "\n",
    "        if not os.path.exists(img_path):\n",
    "            print(f\"[Error]: Image file not found: {img_path}\")\n",
    "            continue\n",
    "\n",
    "        with Image.open(img_path) as img:\n",
    "            if img.size != target_size: \n",
    "                wrong_image_ids.append(img_id)\n",
    "\n",
    "    return wrong_image_ids\n",
    "\n",
    "\n",
    "def load_images_with_resize(missing_part_images_ids, dataset, coco):\n",
    "    for image_id in missing_part_images_ids:\n",
    "        # Load original image\n",
    "        img_info = coco.loadImgs(image_id)[0]\n",
    "        image_path = os.path.join(dataset.root, img_info[\"file_name\"])\n",
    "        original_image = np.array(Image.open(image_path).convert(\"RGB\"))\n",
    "\n",
    "        plt.figure(figsize=(20, 10))\n",
    "\n",
    "        # Display original image\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(original_image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\n",
    "            f\"Original Image - {original_image.shape[1]}x{original_image.shape[0]}\"\n",
    "        )\n",
    "\n",
    "        # Find the image we want\n",
    "        sample = dataset[dataset.img_ids.index(image_id)]\n",
    "        transformed_image = (sample[\"image\"].permute(1, 2, 0).cpu().numpy())\n",
    "        transformed_mask = (sample[\"masks\"].cpu().numpy()) \n",
    "        new_height, new_width = transformed_image.shape[:2]\n",
    "\n",
    "        # Resized\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(transformed_image)\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Resized Image - {new_height}x{new_height}\")\n",
    "\n",
    "        # Resized with mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(transformed_image)\n",
    "        plt.imshow(transformed_mask, cmap=\"gist_ncar\", alpha=1.0, interpolation=\"nearest\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(\"Resized Image with Mask Overlay\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Initialize COCO and dataset\n",
    "annotation_file = \"turtles-data/data/updated_annotations.json\"\n",
    "coco = COCO(annotation_file)\n",
    "\n",
    "\n",
    "# Transform all images into the custom dataset.\n",
    "dataset = customTurtleDataset(\n",
    "    root=\"turtles-data/data\",\n",
    "    annotation=\"turtles-data/data/updated_annotations.json\",\n",
    "    transforms=resize_transform,\n",
    ")\n",
    "\n",
    "wrong_size_image_ids = get_wrong_size_image_ids(\"turtles-data/data\", coco)\n",
    "\n",
    "print(f\"----------------- Wrong Size Image IDs -----------------\\n\")\n",
    "\n",
    "print(f\"Number of images with wrong size: {len(wrong_size_image_ids)}\")\n",
    "print(f\"Note: These images will be differently colored in the display but that is just normalisation from albumentations.\\n\")\n",
    "\n",
    "print(f\"Now processing the images to be displayed . . .\\n\")\n",
    "\n",
    "\n",
    "# ----------------- Displaying the images ------------------\n",
    "# As always, make sure to unload these cells before pushing\n",
    "# to git to avoid making the file too large.\n",
    "# Clear the output of the cells above before pushing to git.\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "load_images_with_resize(wrong_size_image_ids, dataset, coco)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since it was stated that tutors will rerun the notebooks, we will use a seed so the result will always be the same no matter who or what or where or when or why or how this notebook is run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "\n",
    "def set_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.15s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import random_split, DataLoader\n",
    "\n",
    "cleaned_dataset = customTurtleDataset(\n",
    "    root=\"turtles-data/data/images\",\n",
    "    annotation=\"turtles-data/data/updated_annotations.json\",\n",
    "    transforms=resize_transform,\n",
    ")\n",
    "\n",
    "training_size = int(0.8 * len(cleaned_dataset))\n",
    "validation_size = len(cleaned_dataset) - training_size\n",
    "\n",
    "print(f\"----------------- Dataset Split -----------------\\n\")\n",
    "print(f\"Training size: {training_size}\")\n",
    "print(f\"Validation size: {validation_size}\\n\")\n",
    "\n",
    "train_set, val_set = random_split(cleaned_dataset, [training_size, validation_size])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_set, batch_size=4, shuffle=True, num_workers=2\n",
    ")\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_set, batch_size=4, shuffle=False, num_workers=2\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
